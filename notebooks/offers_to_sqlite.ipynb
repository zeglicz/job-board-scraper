{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from requests_cache import CachedSession\n",
    "from requests.exceptions import RetryError, RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dotenv_values(\"../.env\")\n",
    "OFFERS_URL = env.get(\"OFFERS_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobOffersFetcher:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str,\n",
    "        cache_name=\"fetcher_cache\",\n",
    "        cache_expire=60,\n",
    "        use_cache=False,\n",
    "        min_delay=1,\n",
    "        max_delay=4,\n",
    "        retries=5,\n",
    "        backoff_range=(1, 4),\n",
    "    ):\n",
    "        if not base_url:\n",
    "            raise ValueError(\"URL is required and cannot be empty\")\n",
    "        self.base_url = base_url\n",
    "        self.min_delay = min_delay\n",
    "        self.max_delay = max_delay\n",
    "        self.retries = retries\n",
    "        self.backoff_range = backoff_range\n",
    "        self.session = self._init_session(cache_name, cache_expire, use_cache)\n",
    "\n",
    "    def _init_session(self, cache_name, cache_expire, use_cache):\n",
    "        backoff_factor = random.uniform(*self.backoff_range)\n",
    "\n",
    "        retry_strategy = Retry(\n",
    "            total=self.retries,\n",
    "            backoff_factor=backoff_factor,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"GET\"],\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "        if use_cache:\n",
    "            session = CachedSession(\n",
    "                cache_name, expire_after=cache_expire, use_cache=True\n",
    "            )\n",
    "        else:\n",
    "            session = requests.Session()\n",
    "\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "\n",
    "        def log_response_hook(response, *args, **kwargs):\n",
    "            logger.info(f\"Hook: {response.status_code} {response.url}\")\n",
    "\n",
    "        session.hooks[\"response\"] = [log_response_hook]\n",
    "\n",
    "        return session\n",
    "\n",
    "    def fetch_page(self, page: int = 1) -> dict:\n",
    "        try:\n",
    "            response = self.session.get(self.base_url, params={\"page\": page})\n",
    "            response.raise_for_status()\n",
    "\n",
    "            return response.json()\n",
    "        except RetryError as e:\n",
    "            raise RuntimeError(f\"All retries failed: {e}\")\n",
    "        except RequestException as e:\n",
    "            logger.error(f\"Request failed: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def fetch_pages(self, max_pages: int = 5):\n",
    "        pages = list(range(1, max_pages + 1))\n",
    "        random.shuffle(pages)\n",
    "\n",
    "        all_data = []\n",
    "\n",
    "        for page in pages:\n",
    "            page_data = self.fetch_page(page)\n",
    "            all_data.extend(page_data.get(\"data\", []))\n",
    "            logger.info(f\"Saved page: {page}\")\n",
    "            time.sleep(random.randint(self.min_delay, self.max_delay))\n",
    "\n",
    "        return {\"data\": all_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_offers_fetcher = JobOffersFetcher(OFFERS_URL)\n",
    "# data = job_offers_fetcher.fetch_pages(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"data\"][199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"offers.json\", \"w\") as f:\n",
    "#     f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobOfferDatabase:\n",
    "    def __init__(self, db_path: Path = Path(\"../data/db/job_offers.db\")):\n",
    "        self.db_path = db_path\n",
    "        self.db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self._create_table()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_int_or_none(val):\n",
    "        if val is None:\n",
    "            return None\n",
    "        return int(bool(val))\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_str(val):\n",
    "        if isinstance(val, str):\n",
    "            return val.strip()\n",
    "        return val\n",
    "\n",
    "    def _create_table(self):\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute(\n",
    "                \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS job_offers (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                slug TEXT,\n",
    "                title TEXT,\n",
    "                requiredSkills TEXT,\n",
    "                niceToHaveSkills TEXT,\n",
    "                workplaceType TEXT,\n",
    "                workingTime TEXT,\n",
    "                experienceLevel TEXT,\n",
    "                employmentTypes TEXT,\n",
    "                categoryId INTEGER,\n",
    "                multilocation TEXT,\n",
    "                city TEXT,\n",
    "                street TEXT,\n",
    "                latitude TEXT,\n",
    "                longitude TEXT,\n",
    "                remoteInterview INTEGER,\n",
    "                companyName TEXT,\n",
    "                companyLogoThumbUrl TEXT,\n",
    "                publishedAt TEXT,\n",
    "                openToHireUkrainians INTEGER,\n",
    "                languages TEXT,\n",
    "                date_fetched TEXT\n",
    "            )\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "    def insert_offer(self, offer: Dict, date_fetched: str):\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute(\n",
    "                \"\"\"\n",
    "            INSERT INTO job_offers (\n",
    "                slug, title, requiredSkills, niceToHaveSkills, workplaceType,\n",
    "                workingTime, experienceLevel, employmentTypes, categoryId, multilocation,\n",
    "                city, street, latitude, longitude, remoteInterview,\n",
    "                companyName, companyLogoThumbUrl, publishedAt, openToHireUkrainians,\n",
    "                languages, date_fetched\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "                (\n",
    "                    self.clean_str(offer.get(\"slug\")),\n",
    "                    self.clean_str(offer.get(\"title\")),\n",
    "                    json.dumps(offer.get(\"requiredSkills\")),\n",
    "                    json.dumps(offer.get(\"niceToHaveSkills\")),\n",
    "                    self.clean_str(offer.get(\"workplaceType\")),\n",
    "                    self.clean_str(offer.get(\"workingTime\")),\n",
    "                    self.clean_str(offer.get(\"experienceLevel\")),\n",
    "                    json.dumps(offer.get(\"employmentTypes\")),\n",
    "                    offer.get(\"categoryId\"),\n",
    "                    json.dumps(offer.get(\"multilocation\")),\n",
    "                    self.clean_str(offer.get(\"city\")),\n",
    "                    self.clean_str(offer.get(\"street\")),\n",
    "                    str(offer.get(\"latitude\")),\n",
    "                    str(offer.get(\"longitude\")),\n",
    "                    self.to_int_or_none(offer.get(\"remoteInterview\")),\n",
    "                    self.clean_str(offer.get(\"companyName\")),\n",
    "                    self.clean_str(offer.get(\"companyLogoThumbUrl\")),\n",
    "                    self.clean_str(offer.get(\"publishedAt\")),\n",
    "                    self.to_int_or_none(offer.get(\"openToHireUkrainians\")),\n",
    "                    json.dumps(offer.get(\"languages\")),\n",
    "                    date_fetched,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def insert_offers(self, offers: List[Dict]):\n",
    "        date_fetched = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        for offer in offers:\n",
    "            self.insert_offer(offer, date_fetched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetcher = JobOffersFetcher(OFFERS_URL)\n",
    "offers = fetcher.fetch_pages()[\"data\"]\n",
    "\n",
    "db = JobOfferDatabase()\n",
    "db.insert_offers(offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"../data/db/job_offers.db\") as conn:\n",
    "    query = \"SELECT * FROM job_offers\"\n",
    "    df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-board-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
